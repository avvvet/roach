services:
  whisper:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: whisper-stt
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    environment:
      # ── Model selection ──────────────────────────────────────────
      # Option 1: Base whisper-small (no fine-tuning)
      # - WHISPER__MODEL=small

      # Option 2: Our fine-tuned Amharic model
      - WHISPER__MODEL=/models/whisper-amharic-ct2
      # ─────────────────────────────────────────────────────────────
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]